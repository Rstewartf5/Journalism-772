---
title: "pre_lab_10.Rmd"
author: "Derek Willis"
date: "2023-08-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Chapter 29

Up to now, we've been looking at patterns in data for what is more than this, or what's the middle look like. We've calculated metrics like per capita rates, or looked at how data changes over time.

Another way we can look at the data is geographically. Is there a spatial pattern to our data? Can we learn anything by using distance as a metric? What if we merge non-geographic data into geographic data?

The bad news is that there isn't a One Library To Rule Them All when it comes to geo queries in R. But there's one emerging, called Simple Features, that is very good.

Go to the console and install it with `install.packages("sf")`

To understand geographic queries, you have to get a few things in your head first:

1.  Your query is using planar space. Usually that's some kind of projection of the world. If you're lucky, your data is projected, and the software will handle projection differences under the hood without you knowing anything about it.
2.  Projections are cartographers making opinionated decisions about what the world should look like when you take a spheroid -- the earth isn't perfectly round -- and flatten it. Believe it or not, every state in the US has their own geographic projection. There's dozens upon dozens of them.
3.  Geographic queries work in layers. In most geographic applications, you'll have multiple layers. You'll have a boundary file, and a river file, and a road file, and a flood file and combined together they make the map. But you have to think in layers.
4.  See 1. With layers, they're all joined together by the planar space. So you don't need to join one to the other like we did earlier -- the space has done that. So you can query how many X are within the boundaries on layer Y. And it's the plane that holds them together.

```{r, echo=FALSE}
knitr::include_graphics("images/geolayers.jpg")
```

## Importing and viewing data

Let's start with the absolute basics of geographic data: loading and viewing. Load libraries as usual.

### Task 1: Load packages

**Task** Run the following code to load packages.

```{r}
library(tidyverse)
library(sf)
library(janitor)
#library(maptools)
```

First: an aside on geographic data. There are many formats for geographic data, but data type you'll see the most is called the shapefile. It comes from a company named ERSI, which created the most widely used GIS software in the world. For years, they were the only game in town, really, and the shapefile became ubiquitous, especially so in government and utilities.

More often than not, you'll be dealing with a shapefile. But a shapefile isn't just a single file -- it's a collection of files that combined make up all the data that allow you to use it. There's a .shp file -- that's the main file that pulls it all together -- but it's important to note if your shapefiles has a .prj file, which indicates that the projection is specified. You also might be working with a GeoDatabase, or a .gdb file. That's a slightly different, more compact version of a Shapefile.

The data we're going to be working with is a Shapefile of Maryland zip codes from the [state's GIS data catalog](https://data.imap.maryland.gov/datasets/38f3f8bc61bb4261b59d71b3642e3cd6_3/explore?location=38.810313%2C-77.268250%2C8.83).

### Task: Load the Maryland zip code map data.

Simlar to `readr`, the `sf` library has functions to read geographic data. In this case, we're going to use `st_read` to read in our zip code data. And then glimpse it to look at the columns.

### Task: Load data

**Task** Run the following code to load data. Describe what you see in the answer space below. What columns exist in this data? **Answer**
I see 526 observation and 8 variables in the data. The zip codes are interesting, because there are two. The first set looks like the GEOID followed by the postal zip code. Zipname appears to be the name of the town or city. Also, shape length, shape area, and some geographical data exits, the latter under the column entitled "geometry." There's also a column that says "existing" in it. 
```{r}
md_zips <- st_read("data/md_zips/BNDY_ZIPCodes11Digit_MDP.shp")

glimpse(md_zips)
```

This looks like a normal dataframe, and mostly it is. We have one row per zipcode, and each column is some feature of that zip code: the fipscode, name and more. What sets this data apart from other dataframes we've used is the last column, "geometry", which is of a new data type. It's not a character or a number, it's a "Multipolygon", which is composed of multiple longitude and latitude values. When we plot these on a grid of latitude and longitude, it will draw those shapes on a map.

Let's look at these zip codes We have 526 of them, according to this data.

### Task: Run code

**Task** Run the following code. Describe the output in the space below: what kind of information does it contain? **Answer** The outcome is you see all the data from above in a neat table that is ordered by "Object ID." 

```{r}
View(md_zips)
```

But where in Maryland are these places? We can simply plot them on a longitude-latitude grid using ggplot and geom_sf.

### Task: Run code

**Task** Run the following code. Describe the output in the space below. **Answer**
Below is a very detailed sub-county map of the state of Maryland. You can see that the closer we get to the DC-Baltiomre urban corridor the more counties seem to appear more closely to one another. The langitude and the lotitidue data are shown along with the map. 

```{r}
md_zips |>
  ggplot() +
  geom_sf() +
  theme_minimal()
```

Each shape is a zip code, with the boundaries plotted according to its degrees of longitude and latitude.

If you know anything about Maryland, you can pick out the geographic context here. You can basically see where Baltimore is and where the borders of the District of Columbia touch Maryland. But this map is not exactly ideal. It would help to have a county map layered underneath of it, to help make sense of the spatial nature of this data.

This is where layering becomes more clear. First, we want to go out and get another shapefile, this one showing Maryland county outlines.

Instead of loading it from our local machine, like we did above, we're going to use a package to directly download it from the U.S. Census. The package is called `tigris` and it's developed by the same person who made `tidycensus`.

In the console, install tigris with `install.packages('tigris')`

Then load it:

### Task: Run code

**Task** Run the following code. Describe the output in the space below. **Answer**

```{r}
# install.packages('tigris')
library(tigris)
```

Now, let's use the counties() function from tigris to pull down a shapefile of all U.S. counties.

### Task: Run code

**Task** Run the following code. Describe the output in the space below. **Answer** The outcome of running the code is that I get a list of 18 columns and 3,234 rows. There are a lot of titles of the columns I am unfamiliar with: LSAD, CLASSFP, MTFCC, etc. All of the numbers are also in quotes. Lastly, there are a ton of counties that are not in Maryland. Cuming, Wahkiakum... I actually don't see any Maryland counties in the viewable data. 

```{r}

counties <- counties()

glimpse(counties)
```

This looks pretty similar to our places shapefile, in that it looked mostly like a normal dataframe with the exception of the new geometry column (this time called `geometry`, which is pretty common).

This county shapefile has all 3233 U.S. counties. We only want the Maryland counties, so we're going to filter the data to only keep Maryland counties. There is no STATE column, but there is a STATEFP column, with each number representing a state. Maryland's FP number is 24.

### Task: Run code

**Task** Run the following code. Describe the output in the space below. **Answer**
When you run the below code you get a dataframe that lays out  the data above in a nice table. Instead of 3,000 some rows we now have only 24 rows which has data from each of Maryland's counties including the city of Baltimore. 

```{r}
md_counties <- counties |>
  filter(STATEFP == "24")

```

To see what this looks like, let's plot it out with ggplot. We can pretty clearly see the shapes of Maryland counties.

### Task: Run code

**Task** Run the following code. Describe the output in the space below. **Answer**
After running the code in the block below, I see a very simple map that outlines the border of the state of Maryland as well as Baltimore and the state's counties. The Chesapeake Bay has disappeared from thte map. 

```{r}
md_counties |>
  ggplot() +
  geom_sf() +
  theme_minimal()
```

With this county map, we can layer our places data.

Something to note: The layers are rendered in the order they appear. So the first geom_sf is rendered first. The second geom_sf is rendered ON TOP OF the first one.

We're also going to change things up a bit to put the datasets we want to display INSIDE of the geom_sf() function, instead of starting with a dataframe. We have two to plot now, so it's easier this way.

### Task: Run code

**Task** Run the following code. Describe the output in the space below. **Answer** 

Running the code in the codeblock below produces a very detailed map that looks similar to one of the first maps we did. It contains several subcounties. The Chesapeake Bay seems to be back, but it's diminished in size. 

```{r}
ggplot() +
  geom_sf(data=md_counties) +
  geom_sf(data=md_zips) +
  theme_minimal()
```

Notice the subtle differences at the boundaries?

Let's dive back into zip codes and this time bring along data on notices of intent to foreclosure by zip code (found at <https://opendata.maryland.gov/Housing/Maryland-Notices-of-Intent-to-Foreclose-by-Zip-Cod/ftsr-vapt>). Where are these foreclosure notices appearing?

### Task: Run code to load the foreclosure notice data.

**Task** Run the following code. Describe the output in the space below. **Answer**
The output of running the below codeblock is a dataframe with two rows: the zip code and what I presume to be the number of foreclosures in the month of March 2023. 

```{r}
foreclosure_zip <- read_csv("data/Maryland_Notices_of_Intent_to_Foreclose_by_Zip_Code.csv") |> clean_names()
foreclosure_zip_march_2023 <- foreclosure_zip |> 
  select(zip, march_2023)

View(foreclosure_zip_march_2023)
```

Now we can join the zip codes to the foreclosure data.

### Task: Run code to join the zip code shapes with the foreclosure notice data

**Task** Run the following code. Describe the output in the space below. **Answer**
When I run the code block below, I see the same data in the md_zips data frame as well as a new column entitled "March 2023." The two dataframes were joined based upon their common column of zip code. 

```{r}
zip_codes_with_foreclosures <- md_zips |> left_join(foreclosure_zip_march_2023, join_by(ZIPCODE1==zip))
```

Now we can use color to distinguish zip codes from each other. Let's use the number of foreclosure notices to start with:

### Task: Run code

**Task** Run the following code. Describe the output in the space below. **Answer**

When we run the code in the code block below you see a map of Maryland divided by zip code. The map is in color - in different shades of blue. Because we specified the aesthetics of the map to use data in the March 2023 row, the "coulours" are changing based upon the number in that row. Smaller numbers are darker blue, and the lighter numbers are lighter blue. 

```{r}
county_centroids <- st_centroid(zip_codes_with_foreclosures)

ggplot() +
  geom_sf(data=zip_codes_with_foreclosures, aes(fill=march_2023)) +
  scale_colour_viridis_b(option="magma") +
  theme_minimal()
```

With these changes, what can we make out here? First, you can pretty easily spot zip codes with a high number of foreclosures - in Prince George's County in particular, along with zip codes around Baltimore and in places in the northeast and northwest parts of the state.

## Chapter 21

In the previous chapter, we looked at foreclosure notices by zip codes to find patterns in Maryland. Let's go further and, instead of using raw numbers, use percentages based on the number of owner-occupied housing units in each county.

First, let's load the libraries we'll need. We're also going to load tidycensus and set an API key for tidycensus.

### Task: Load libraries

**Task** Run the following code. Describe the output in the space below. Be sure to input your census api key. **Answer**
The output is that I've loaded additional libraries. Nothing else seemed to happen. 

```{r}
library(tidyverse)
library(sf)
library(janitor)
library(tidycensus)
#census_api_key("549950d36c22ff16455fe196bbbd01d63cfbe6cf")
```

For the rest of this chapter, we're going to work on building a map that will help us gain insight into geographic patterns in foreclosure notices by county in Maryland. What geographic patterns can we identify?

First, we'll go out and get the county foreclosure notices and population data for each county using tidycensus. The variable for total population is B01001_001

### Task: Run code

**Task** Run the following code. Describe the output in the space below. **Answer** 

The output of running that code is I get a new dataframe called "md_county_notices from the foreclosure data. Then, I also get a data frame called md_county_population with 24 rows and five columns.  

```{r}
md_county_notices <- read_csv("data/Maryland_Foreclosure_Data_by_County.csv") |> slice(1) |> pivot_longer(cols=-c('Date', 'Type'), names_to='county', values_to = 'notices')

md_county_population <- get_acs(geography = "county",
              variables = c(population = "B01001_001"),
              year = 2021,
              state = "MD")
```

Ultimately, we're going to join this county table with population with foreclosure notices by county, and then calculate a percentage. But remember, we then want to visualize this data by drawing a zip code map that helps us pick out trends. Thinking ahead, we know we'll need a zip code map shapefile. Fortunately, we can pull this geometry information right from tidycensus at the same time that we pull in the population data by adding "geometry = TRUE" to our get_acs function.

### Task: Run code

**Task** Run the following code. Describe the output in the space below. **Answer** When I ran that code I got the same data for the dataframe md_county_population, but this time I got an extra column with geographic data. Multipolygon geography. 

```{r}
md_county_population <- get_acs(geography = "county",
              variables = c(population = "B01001_001"),
              year = 2021,
              state = "MD",
              geometry = TRUE)

md_county_population
```

We now have a new column, geometry, that contains the "MULTIPOLYGON" data that will draw an outline of each county when we go to draw a map.

The next step will be to join our population data to our foreclosure data on the county column.

But there's a problem. The column in our population data that has county names is called "NAME", and it has the full name of the county spelled out in title case -- first word capitalized and has "County" and "Maryland" in it. The foreclosure data just has the name of the county. For example, the population data has "Anne Arundel County, Maryland" and the foreclosure data has "Anne Arundel County".

### Task: Run code

**Task** Run the following code. Describe the output in the space below. **Answer** The counties contain different information in the separate dataframes. In one, the counties are followed by the state of Maryland. In the other, they are not. In one there's an additional row as well. 

```{r}
md_county_population

md_county_notices
```

If they're going to join properly, we need to clean one of them up to make it match the other.

Let's clean the population table. We're going to rename the "NAME" column to "county", then remove ", Maryland" and make the county titlecase. Next we'll remove any white spaces after that first cleaning step that, if left in, would prevent a proper join. We're also going to rename the column that contains the population information from "estimate" to "population" and select only the county name and the population columns, along with the geometry. That leaves us with this tidy table.

### Task: Run code

**Task** Run the following code. Describe the output in the space below. **Answer**

The data in the county column is now in title case and it now no longer has the word "Maryland" following it. Also, we've selected the only the rows we need from this data frame. The column for MOE and the column for variable are no longer there, clouding up our dataframe with information we don't need. 
```{r}
md_county_population <- md_county_population |>
  rename(county = NAME) |>
  mutate(county = str_to_title(str_remove_all(county,", Maryland"))) |>
  mutate(county = str_trim(county,side="both")) |>
  rename(population = estimate) |>
  select(county, population, geometry)

md_county_population
```

Now we can join them!

### Task: Run code

**Task** Run the following code. Describe the output in the space below. **Answer** The result is that dat from the two dataframes "md_county_population" and md_county_notices" have now successfully joined with each other. 

```{r}
md_pop_with_foreclosures <- md_county_population |>
  left_join(md_county_notices, join_by(county))

md_pop_with_foreclosures
```

Our final step before visualization, let's calculate the number of foreclosure notices per 1000 population and sort from highest to lowest to see what trends we can identify just from the table.

### Task: Run code

**Task** Run the following code. Describe the output in the space below. **Answer**

The output is the same dataframe as before, but it also has an additional column added to the right that shows the RATE of foreclosures. Using the rate allows us to better understand how important the dynamic of forclosrues versus just seeing the number of forclosures. 
```{r}
md_pop_with_foreclosures <- md_county_population |>
  left_join(md_county_notices, join_by(county)) |> 
  mutate(rate = notices/population*1000) |>
  arrange(desc(rate))

md_pop_with_foreclosures
```

Let's take a look at the result of this table. The variances in the rates aren't huge, but there are some clear differences: Charles County and Prince George's County have higher rates, followed by Baltimore City and some more rural counties.

Okay, now let's visualize. We're going to build a choropleth map, with the color of each county -- the fill -- set according to the number of notices per 1K population on a color gradient.

### Task: Run code

**Task** Run the following code. Describe the output in the space below. **Answer** You get a monochromatic blue map with the langitude and longitude splayed out in the background, a color coded legend, and county names labeled across the map. County names are sometimes hard to see, because they disappear into the darker background colors. 

```{r}

county_centroids <- st_centroid(md_counties)
county_centroids_df <- as.data.frame(st_coordinates(county_centroids))
county_centroids_df$NAME <- county_centroids$NAME

ggplot() +
  geom_sf(data=md_pop_with_foreclosures, aes(fill=rate)) +
  geom_text(aes(x = X, y = Y, label = NAME), data = county_centroids_df, size = 3, check_overlap = TRUE) +
  theme_minimal()
```

This map is okay, but the color scale makes it hard to draw fine-grained differences. Let's try applying the magma color scale we learned in the last chapter.

### Task: Run code

**Task** Run the following code. Describe the output in the space below. **Answer** The county labels have been removed from the map, and there's a weird beige, pink,purple, black spectrum of colors on the map. You can more easily see the outliers in the data visually. Garret, Montgomery, and Howard counties have the least rate of foreclosures, whereas Charles County clearly has the most. I would invert the colors though, because I think associating least with the darkest color is not intuitive. Lighter colors tend to signify the absence of something, right? 

```{r}
ggplot() +
  geom_sf(data=md_pop_with_foreclosures, aes(fill=rate)) +
  theme_minimal() +
  scale_fill_viridis_b(option="magma")
```

The highest ranking counties stand out nicely in this version, but it's still hard to make out fine-grained differences between other counties.

So let's change the color scale to a "log" scale, which will help us see those differences a bit more clearly.

### Task: Run code

**Task** Run the following code. Describe the output in the space below. What regional patterns do you see? **Answer**

The map becomes more sectioned off. Frederick County joins Howard and Montgomery counties in central Maryland visually as not having as significant of a foreclosure rate. Wicomico and Talbot counties on the eastern shore as well. Charles county remains an outlier visually. It's hard to see any regional patterns that make sense to me. 
```{r}
ggplot() +
  geom_sf(data=md_pop_with_foreclosures, aes(fill=rate)) +
  theme_minimal() +
  scale_fill_viridis_b(option="magma",trans = "log")
```
