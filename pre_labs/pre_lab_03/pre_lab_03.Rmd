---
title: "pre_lab_03.Rmd"
author: "Derek Willis"
date: "2023-08-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
```

## About this notebook

This notebook contains code and explanatory text that your should review and run as you read through two chapters on data cleaning from the course textbook, "Data Journalism with R and the Tidyverse". Answer questions and edit the document as directed.

Running this notebook will help you understand key data analysis methods and concepts that you will put into practice during this week's lab.

When you are finished running the code in this notebook, you will push changes to your course GitHub repo, and upload the link to ELMS as instructed.

## Data Cleaning, Part I

### Task 1: Load libraries and settings

**Task** Run the following code in the gray-colored codeblock below to load the tidyverse library and turn off scientific notation.

```{r}
# Remove scientific notation
options(scipen=999)
# Load the tidyverse   
library(tidyverse)
```

### Task 2: Load data

**Task** Load some [Maryland state government payments data](https://opendata.maryland.gov/Budget/State-of-Maryland-Payments-Data-FY2008-to-FY2024/7syw-q4cy) by running the following code. We'll use the guess_max() function as an argument to use the first 10 rows to set the data type. What does the first line of the red Warning message that prints out when you load the data say? What happens when you follow its instructions? Answer below. **Answer** The first line of the red warning messages recommends that we run the problems()function to see what the issue was. When I follow the instructions the function produces a table with 350 rows of parsing problems. 
```{r}
problems(payments)

```

```{r}
payments <- read_csv("data/State_of_Maryland_Payments_Data__FY2008_to_FY2024.csv", guess_max=10)
```

### Task 3: Reload data

**Task** Run the following codeblock to reload the data, using every row to set the data types. Does it show any parsing errors when you run? Answer below **Answer** No warning came up, so I believe that means there are no parsing errors.  

```{r}
payments <- read_csv("data/State_of_Maryland_Payments_Data__FY2008_to_FY2024.csv", guess_max=373564)
```

### Task 4: Examine the data with glimpse

**Task** Run the following codeblock to glimpse the data. What data type is the "Vendor Name" field? What data type is the "Amount" field? What data type is the "Date" column? Answer below. **Answer** The vendor name field is a character. The amount field is a number. The date column field is a character. 

```{r}
glimpse(payments)
```

Things that should be characters -- like agency name, vendor name -- are characters (chr). Things that should be numbers (dbl) -- like amount and fiscal year -- are numbers. We've seen before that sometimes dates aren't defined as date datatypes by R - we can fix that using `lubridate`.

### Task 5: Detect wrong spatial data

The second smell we can find in code is **wrong spatial data**. Spatial data means data that refers to some geography; in this dataset the only geographical element is the vendor's zip code. Zip codes should be, at a minimum, five characters long (although composed of numbers, zip codes aren't used as numbers).

We can check to see if any of the zip codes are less than five characters by using [a function called `str_length`](https://stringr.tidyverse.org/reference/str_length.html) inside a filter.

**Task** Run the following codeblock to group by the vendor's zip code and show any that are less than five characters in length. How many zip codes do not have five characters? What do you think explains those records? 
**Answer**
549 rows do not have five character zip codes. Something must have happened in the data entry stage. Perhaps someone entered in a wrong zip code - missed a number. 

```{r}
payments |>
  group_by(`Vendor Zip`) |>
  filter(str_length(`Vendor Zip`) < 5) |> 
  summarise(
    count=n()
  ) |>
  arrange(desc(count))
```

### Task 6: Load Maryland grant and loan data

Let's now look at **gaps in data**. These often occur when you have a date or time element in your data, but there are other potential gaps, too. To illustrate those, we're going to introduce some Maryland state grant and loan data from 2009 forward. Let's load it and take a look:

**Task** Run the following codeblock to load Maryland state government grant and loan data

```{r}
md_grants_loans <- read_csv("data/State_of_Maryland_Grant_and_Loan_Data__FY2009_to_FY2022.csv")
```

Each row represents a recipient of state grant or loan, along with information about their location and the state agency that provided the money. When we talk about gaps, often they indicate the administrative rules. Here's an example: let's count the number of payments in each category (Grant or Loan) by year in this dataset.

### Task 7: Looking at categories

**Task** Run the following codeblock and describe below what each line is doing. Looking at the results, what jumps out at you as potentially problematic?
**Answer**
 Each line is showing how many grants, loans, or contracts were given per year. The lines that have no category are potentially problematic. 

```{r}
md_grants_loans |> 
  group_by(`Fiscal Year`, Category) |> 
  summarize(count = n()) |> 
  arrange(`Fiscal Year`)
```

Any time you are going to focus on a column for analysis, you should check for unusual values. Are there any unusually large values or unusually small values? Are there any values that raise immediate questions about the data? Let's look at the smallest amounts in the grants and loan data.

### Task 8: Find outliers

**Task** Run the following code to arrange the grants & loan data so that the smallest amount is first. Describe what you see.  
**Answer**
My first instinct was that it seemed strange to have a grant amount that was $60. The grants that were for a strange amount of cents also seemed strange 379.38 or 361.81. These are very specific numbers, and any time I've come across grants they are usually rounded numbers like 380 or 400. 

```{r}
md_grants_loans |> 
  arrange(Amount)
```

## Data Cleaning, Part II

### Task 1: Install janitor

**Task** Run the following codeblock to install the janitor package.

```{r}
install.packages('janitor')
```

### Task 2: Load janitor

**Task** Run the following code to load janitor.

```{r}
library(janitor)
```

Let's continue with our Maryland grants and loans data that we worked with in the previous chapter. There are a number of issues with this data set that might get in the way of asking questions and receiving accurate answers. They are:

-   The column names have spaces in them. This isn't a deal-breaker, as we used this dataframe previously. But it does require that you do some things differently when writing code, and ideally you don't want spaces in your column names.
-   Inconsistent capitalization across multiple columns. Sometimes the grantee is capitalized, and other times not. Portions of the grantor name are sometimes capitalized. This issue will ruin your ability to count and add things using those columns.
-   The zip field mixes five digit ZIP codes and nine digit ZIP codes, and some of the records include spaces. If we wanted to group and count the number of loans in a given ZIP code, this inconsistency would not let us do that correctly.
-   The category column is inconsistent and has some missing values.

Let's get cleaning. Our goal will be to build up one block of code that does all the necessary cleaning in order to answer this question: which zip code has gotten the most amount of money from the Maryland Tourism Board?

### Task 3: Use clean_names()

**Task** Run the following codeblock to use the `clean_names()` function from janitor to standardize column names. How does it change the headers? Answer below.
**Answer**
the headers all now begin with lowercase letters. Before, I believe some began with upper case letters. Secondly, there are no longer any spaces in the headers where there are two words. Zip code and Fiscal year became zip_code and fiscal_year. 

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names()

# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 4: Use rename()

**Task** Run the following codeblock to use the clean_names() function from janitor to standardize column names and then use rename() to change the "grantor" column to "source". With `rename()` the new name comes first!

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor)

# display the cleaned dataset
cleaned_md_grants_loans
```

Right now the `source`, `grantee` and `description` columns have inconsistent capitalization. We can fix that using a mutate statement and a function that changes the case of text called `str_to_upper()`. We'll use the same columns, overwriting what's in there since all we're doing is changing case.

### Task 5: Using str_to_upper() to standardize case

**Task** Run the following codeblock to use str_to_upper() to make the source, grantee and description columns upper-cased. Describe what each line is doing.
**Answer** 
lines 187 and 188 are gearing up the clean names function for the md grants data. Line 189 is a code to change the column with the name grantor to the name source and column 190 is telling r studio to find the columns called source, grantee, and description, and to change all the letters in these columns to uppercase letters. Line 192 tells R studio to display the subsequent data set. 
```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor) |> 
  mutate(source = str_to_upper(source), grantee = str_to_upper(grantee), description = str_to_upper(description))

# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 6: Check for duplicate rows

**Task** Run the following codeblock to check for duplicate rows using get_dupes(). How many duplicates are possible? 
**Answer**
there are 50 duplicates. 

```{r}
cleaned_md_grants_loans |>
  get_dupes()
```

### Task 7: Get rid of duplicate rows

**Task** Run the following codeblock to use distinct() to get rid of duplicate rows. How many rows does the new dataframe have? Answer below. 
**Answer**
The new data set has 17,740 rows

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor) |> 
  mutate(source = str_to_upper(source), grantee = str_to_upper(grantee), description = str_to_upper(description)) |> 
  distinct()

# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 8: Clean up ZIP code

The rest of the problems with this data set all have to do with inconsistent format of values in a few of the columns. To fix these problems, we're going to make use of mutate() in concert with "string functions" -- special functions that allow us to clean up columns stored as character strings. The tidyverse package `stringr` has lots of useful string functions that you can look up!

Let's start by cleaning up the zip field. Remember, some of the rows had a five-digit ZIP code, while others had a nine-digit ZIP code, separated by a hyphen or not.

We're going to write code that tells R to make a new column for our zips, keeping the first five digits on the left, and get rid of anything after that by using `mutate()` in concert with `str_sub()`, from the `stringr` package.

**Task** Run the following codeblock to use str_sub() to convert the ZIP codes that have nine digits to five digits, creating a new column. Look at the difference in the result - what changed? 
**Answer**

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor) |> 
  mutate(source = str_to_upper(source), grantee = str_to_upper(grantee), description = str_to_upper(description)) |> 
  distinct() |>
  mutate(zip5 = str_sub(zip_code, start=1L, end=5L))


# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 9: Clean up zip5 field more with case_when()

**Task** Run the following codeblock to use case_when() to change clear non-zip codes into NA values.

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor) |> 
  mutate(source = str_to_upper(source), grantee = str_to_upper(grantee), description = str_to_upper(description)) |> 
  distinct() |>
  mutate(zip5 = str_sub(zip_code, start=1L, end=5L)) |>
  mutate(zip5 = case_when(
    zip5 == "Vario" ~ NA,
    zip5 == "UB7 O" ~ NA,
    zip5 == "UB7 " ~ NA,
    .default = zip5
  ))

# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 10: Answer our question!

**Task** Write and run code to answer our original question: which zip code has gotten the most amount of money from the Maryland Tourism Board? Where is that zip code, and does that zip code make sense to you as the top recipient? Write a sentence describing the top result.
**Answer**
The zip code with the most amount of money from the Maryland Tourism Board is 21201. That makes sense because the area consists of downtown Baltimore including Penn Station, the Orioles stadium, the convention center, and other important historic sites that bring the city money. I'm assuming grants are given for need and need may be articulated in terms of potential revenue for the city. 

```{r}
cleaned_md_grants_loans|> 
  group_by(zip5)|>
  summarize (count = n())|>
  arrange(desc(count))

```
